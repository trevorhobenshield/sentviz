{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f57a08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from IPython.core.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu';print(f'Using {device}')\n",
    "load_dotenv()\n",
    "\n",
    "S = {'NEGATIVE': 'red', 'NEUTRAL': 'yellow', 'POSITIVE': 'green'}\n",
    "\n",
    "Label = Enum('Label', 'NEGATIVE NEUTRAL POSITIVE', start=0)\n",
    "\n",
    "\n",
    "def view(df_, *args, **kwargs):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None):\n",
    "        if args:\n",
    "            if args[0] == -1:  # view all\n",
    "                display(HTML(df_.head(len(df_)).to_html()))\n",
    "            else:\n",
    "                display(HTML(df_.head(args[0]).to_html()))\n",
    "                display(HTML(df_.tail(args[1]).to_html()))\n",
    "        elif kwargs:\n",
    "            display(HTML(df_.head(kwargs['head']).to_html()))\n",
    "            display(HTML(df_.tail(kwargs['tail']).to_html()))\n",
    "\n",
    "\n",
    "def convert_label(clf_output):\n",
    "    return Label(int(clf_output['label'].split('_')[-1])).name\n",
    "\n",
    "\n",
    "def query_transcript(d, q, w, f):\n",
    "    \"\"\"\n",
    "    d:  dataframe     - DataFrame containing trascript text and urls\n",
    "    w:  width         - How much many surrounding text entries to include from the dataframe\n",
    "                        as context for the query.\n",
    "    q:  query         - The keyword or phrase to search in the transcript.\n",
    "    f: regex flag\n",
    "    \"\"\"\n",
    "    match_idxs = d.query('text.str.contains(@q,regex=True,flags=@f)', engine='python').index.values\n",
    "    match_text = [' '.join(d.loc[i - w:i + w].text).replace('\\n', ' ') for i in match_idxs]\n",
    "    match_df = d.loc[match_idxs]\n",
    "    return match_text, match_df\n",
    "\n",
    "\n",
    "def infer(clf, text):\n",
    "    return [{'label': convert_label(d), 'score': d['score']} for d in clf(text)]\n",
    "\n",
    "\n",
    "def sent_df(text, sent):\n",
    "    return pd.DataFrame([a | b for a, b in zip([{'text': t} for t in text], sent)])\n",
    "\n",
    "\n",
    "def colour_df(sent_slice):\n",
    "    return sent_slice.style.apply(lambda x: [\n",
    "        \"background:red\" if 'NEGATIVE' in x.iloc[0] else \"background:green\" if 'POSITIVE' in x.iloc[\n",
    "            0] else \"background:yellow\" for v in x], axis=1, subset='label')\n",
    "\n",
    "def viz(sent,sent_slice):\n",
    "    try:\n",
    "        fig = px.pie(sent, names='label', color='label', color_discrete_map=S, width=400, height=400)\n",
    "        fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "        fig.show()\n",
    "        return colour_df(sent_slice)\n",
    "    except:\n",
    "        print('no matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('transcript.parquet')\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db287f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "clf = pipeline(\n",
    "    task='sentiment-analysis',\n",
    "    model=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0f56c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_text, match_df = query_transcript(df, ' fuck ', 1, re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e109cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = infer(clf, match_text)\n",
    "sents = sent_df(match_text, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d1d80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n"
     ]
    }
   ],
   "source": [
    "viz(sents,sents[:10]) # pass a slice, don't print the entire df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
